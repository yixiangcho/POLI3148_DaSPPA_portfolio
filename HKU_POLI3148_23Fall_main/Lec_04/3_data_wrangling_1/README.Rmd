---
title: "Data Wrangling (1)"
author: "Haohan Chen"
date: "Last update: `r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document: default
  pdf_document: default
  md_document: default
knit: (function(inputFile, encoding){rmarkdown::render(inputFile, encoding = encoding, output_format = "all", knit_root_dir = getwd())})
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objectives of this Lecture

This lecture introduces data wrangling with R. Using V-Dem data as an example, we will learn how to use the wrangle data with a set of [`tidyverse`](https://www.tidyverse.org/) functionality. Specifically, we will focus on functions...

1.  to import and export data: `read_csv` , `write_csv` (with a brief introduction to other data import/ export functions from [`readr`](https://readr.tidyverse.org/)).

2.  to take a subset of *columns* in the existing data: `select`

3.  to rename columns: `rename`

4.  to take a subset of *rows* by some simple conditions: `slice_`

5.  to take a subset of *rows* by some more complicated conditions: `filter`

6.  to sort the rows based on the value of one or multiple columns: `arrange`

7.  to perform (4) (5) (6) group by group: `group_by`, `ungroup`

8.  to create new columns in the data: `group_by`, `mutate`, `ungroup`

9.  to summarize the data: `group_by`, `summarise`, `ungroup`

## Outline of In-Class Demo

To demonstrate the above functionality, we will use real-world political data from [V-Dem](https://v-dem.net/). Specifically, we will use the above function to explore the state of global economic development from 1984 to 2022. Our effort will take the following step (with one-on-one mappings with the above tools).

1.  Read a part of pre-processed V-Dem data into R: 1984-2022 "external" data in the V-Dem dataset.
2.  Consulting the dataset's [codebook](https://github.com/haohanchen/HKU_POLI3148_23Fall/blob/main/_DataPublic_/vdem/documentation/codebook_v13.pdf) and take a **subset** of indicators of *economic development* (along with country-year identifiers).
    -   *See a list of country-yer identifiers on p. 5 of the codebook (under "1.7 Identifier Variables in the V-Dem Datasets").*

    -   *See a list of development indicators on p. 23 of the codebook (under "9. Background Factors").*
3.  Rename the column to name their names informative to readers.
4.  Find the country-year with the *highest* and *lowest* level of economic development. In addition, create a dataset containing a random sample of country-year in the dataset.
5.  Create a dataset focusing on the economic development of Asian countries and regions; Create a dataset that contains only countries/ regions whose development level pass certain threshold.
6.  Create a dataset whose rows are sorted by the development level of country-year.
7.  Create a dataset that contains the year of the higest development level for each country/ region respectively.
8.  Add the following economic indicators to the data:
    1.  Country-year development level with reference to that of 1984.

    2.  Year-on-year economic growth.
9.  Perform a data availability/ integrity check. Then aggregate the data into a new country-level dataset which contains the following indicators:
    1.  Average development level from 1984 to 2022.

    2.  Magnitude of growth from 1984 to 2022.

## In-Class Exercise

The quality of education has a decisive effect on a country's future development. Applying the data wrangling tools we introduce in this lecture, perform the following task:

1.  **Coodbook lookup**. Look up the codebook, answer the following questions:
    1.  What indicators regarding the quality of education are available in the V-Dem datasets?

    2.  What are the data's coverage (i.e., for which countries and years do we have data?)

    3.  What are their sources? Provide the link to least 1 source.
2.  **Subset by columns**
    1.  Create a dataset containing only the country-year identifiers and indicators of education quality.

    2.  Rename the columns of education quality to make them informative.
3.  **Subset by rows**
    1.  List 5 countries-years that have the highest education level among its population.

    2.  List 5 countries-years that suffer from the most severe inequality in education.
4.  **Summarize the data**
    1.  Check data availability: For which countries and years are the indicators of education quality available?

    2.  Create two types of country-level indicators of education quality

        1.  Average level of education quality from 1984 to 2022

        2.  Change of education quality from 1984 to 2022

    3.  Examine the data and *briefly* discuss: Which countries perform the best and the worst in terms of education quality in the past four decades?

**Submission requirement:** You will submit your outputs through Moodle. In your submission:

1.  Attach a PDF document rendered by Rmarkdown
2.  In the text field of your submission, include the link to the corresponding Rmarkdown file in your *DaSPPA portfolio* GitHub repo.

**Due:** October 6, 2023

*Note:* *Please* *only use the functions we cover in this lecture for this exercise. There is [absolutely no need]{.underline} to perform any data visualization for this exercise... We will get there in later lectures.*

## Further reading

-   R for Data Science (2e) Chapters 4, 5, 8: <https://r4ds.hadley.nz/>

-   `readr` documentation (note: read the "cheatsheet"): <https://readr.tidyverse.org/>

-   `dplyr` documentation (note: read the "cheatsheet"): <https://dplyr.tidyverse.org/>

-   V-Dem documentation: <https://v-dem.net/>

## Demo

### 0. Load the `tidyverse` Packages

This section loads the packages we need in this lecture.

```{r}
library(tidyverse)
```

### 1. Import and Export the V-Dem Data

This section loads the VDEM dataset and describe its basic information

```{r}
d <- read_csv("_DataPublic_/vdem/1984_2022/vdem_1984_2022_external.csv")
```

### 2. Select economic development indicators

We start by examining the dataset. `name()` is almost always the first function I apply to a dataset. It gives us the names of all the columns

```{r}
names(d)
```

We may use some alternative functions that provides information about the dataset. The `str()` provides not only variable names, but also their data types and a few example data points.

```{r}
# Warning: If you have many variables, the output of str() will be lengthy!
str(d)
```

Usually, the second step of my data inquiry is having an overview of the *identifiers* of data points. In our case, the identifiers are country names, country IDs, and years. Using the `distinct()` function can effectively identify the distinct levels of *identifiers*

```{r}
d |> select(country_name, country_id, year) |> distinct()
```

```{r}
# Which countries are in this dataset
d |> select(country_name) |> distinct()
```

```{r}
d |> select(year) |> distinct()
```

Select both the country identifiers, GDP, and GDP per capita.

```{r}
d_gdp <- d |> 
  select(country_name, country_id, year, e_gdp, e_gdppc)

d_gdp
```

### 3. Rename Columns to Make Names Informative

```{r}
# d_gdp |>
#   rename("GDP" = "e_gdp", "GDP_per_capita" = "e_gdppc",
#          "Country" = "country_name", "ID" = "country_id",
#          "Year" = "year")

d_gdp <- d_gdp |>
  rename("GDP" = "e_gdp", "GDP_per_capita" = "e_gdppc",
         "Country" = "country_name", "ID" = "country_id",
         "Year" = "year")

d_gdp
```

### 4. Subset Rows of the Data Using `slice_`

The set of `slice_` functions will become handy when you want to take a subset of rows based on some simple rules.

If you would like to get 10 obervations (countries-years) with the maximum `GDP`, use `slice_max`:

```{r}
# Want countries-years with highest GDP
d_gdp |> slice_max(order_by = GDP, n = 10)
```

Similiarily, if you want a subset of countries-years with mimnimal GDP, use `slice_min`:

```{r}
# Get countries-years with the lowest GDP
d_gdp |> slice_min(order_by = GDP, n = 10)
```

Finally, if you wish to take a random sample of observations in the data, use `slice_sample`. Note that you may tell R the exact sample size you want:

```{r}
set.seed(52)
d_gdp |> slice_sample(n = 10) # Sample 10 observations
```

Or you may define the sample size as a poroportion of the original data size:

```{r}
set.seed(52)
d_gdp |> slice_sample(prop = 0.1)
```

The `set.seed` function specify a random seed with which the system uses to generate the "random sample." Long story short, "random" stuff generated by a machine are never really random. Instead, the random outputs (in our case, a random subset of the data) are results of the computer input some "random seed" to some complicated formula. When you define a random seed, you can guarantee that you obtain the same random sample every time you run the program -- this makes your data science research reproducible. As we have discussed, reproducibility is a desired feature of a data science project. So I would strongly recommend setting a random seed every time.

### 5. Subset Rows of the Data Using `filter`

For example, we may take the observations whose `Year` variable ranges from 2000 to 2005.

```{r}
# Want: 2000-2005 data
d_gdp |> filter(Year >= 2000 & Year <= 2005)
```

We may subset observations whose `Country` variable, a `character` variable, equals to the text `"China"`.

```{r}
d_gdp_china <- d_gdp |> filter(Country == "China")
```

We may also stack multiple `filter` functions. For example, you may do the following if you want to look at a subset of the data whose `Year` ranges from 2000 to 2005 and `Country` equals to `"China"`:

```{r}
# Want: 2000 - 2005 from China
d_gdp |> 
  filter(Year >= 2000 & Year <= 2005) |> 
  filter(Country == "China")
```

### 6. Sort the Data based on Values of Rows using `arrange`

Now we will try to sort the dataset `d_gdp` by the value of GDP per capita using the `arrange`. We may have country-year with small values of `GDP_per_capita` appearing first and those with larger values of `GDP_per_capita` coming after them.

```{r}
# Want: sort the row by GDP per capita
d_gdp |> arrange(GDP_per_capita)
```

Want the countries-years with larger values of `GDP_per_capita` appear first? Simply reverse the value using `-GDP_per_capita`. Alternatively, you may replace `desc(GDP_per_capita)`.

```{r}
d_gdp |> arrange(-GDP_per_capita)

d_gdp |> arrange(desc(GDP_per_capita))
```

### 7. Perform (4) (5) (6) group by group: `group_by`, `ungroup`

**Task 1:** Create a dataset that, for each country, include the country-year with the highest GDP.

```{r}
# Want: For each country, we want the year with the highest GDP
d_gdp_highest <- d_gdp |>
  group_by(Country) |>
  slice_max(GDP, n = 1)

nrow(d_gdp_highest)
```

Note: As you may recall, there are 181 distinct countries in this dataset. However, the number of observations as output is 341. That means there are duplicates. What may cause duplication? The straightforward way to go (especially for small dataset) is to manually examining the data.

```{r}
d_gdp_highest
```

Upon examination, the cause of duplicates is that some countries or regions have no GDP data. In these cases, there is naturally no way for `slice_` function to find a maximum or a minimum. So it includes all! Hong Kong is an example:

```{r}
d_gdp_highest |> filter(Country == "Hong Kong")
```

To remove these cases, we have two options: (1) we can use `filter` to remove observations whose `GDP` column is `NA`; (2) we can look up `slice_` 's documentation and see if there is a way to remove `NA` cases. I'd go for the latter.

```{r}
# Filter out NA cases with the filter() function
d_gdp_highest <- d_gdp |> 
  group_by(Country) |>
  slice_max(GDP, n = 1) |>
  filter(!is.na(GDP))

# specify arguments for the slice_max() function to remove NA cases
d_gdp_highest <- d_gdp |>
  group_by(Country) |>
  slice_max(GDP, n = 1, na_rm = TRUE)
```

**In-class exercise:** Create a dataset that, for each country, include the country-year with the lowest GDP.

```{r}
d_gdp_lowest <- d_gdp |>
  group_by(Country) |>
  slice_min(GDP, n = 1, na_rm = TRUE)

d_gdp_lowest
```

### 8. Create new columns in the data: `group_by`, `mutate`, `ungroup`

```{r}
d_gdp |> mutate(New = 1)

d_gdp |> mutate(New = GDP)

d_gdp |> mutate(New = log(GDP))
d_gdp |> mutate(New = log(GDP) + 1)

# Want: New column to be GDP relative to average GDP in the world 1984-2022
d_gdp |> mutate(GDP_over_avg = GDP / mean(GDP, na.rm = TRUE))

# Want: New column to be GDP relative to average GDP of the country in the world 1984-2022
d_gdp |> 
  group_by(Country) |>
  mutate(GDP_over_avg = GDP / mean(GDP, na.rm = TRUE))
```

**Task:** Add the following economic indicators to the data:

1.  Country-year development level with reference to that of 1984.

2.  Year-on-year economic growth.

```{r}
# Country-year development level with reference to that of 1984.
d_gdp |>
  group_by(Country) |>
  arrange(Year) |>
  mutate(GDP_over_1984 = GDP / first(GDP)) |>
  ungroup() |>
  arrange(Country, Year)

# first()
```

```{r}
# Country-year development level with reference to that of 1984.
d_gdp
```

```{r}
# Year-on-year economic growth.
# ?lag

d_gdp |>
  group_by(Country) |>
  arrange(Year) |>
  mutate(GDP_yoy_change = GDP - lag(GDP, n = 1)) |>
  ungroup() |>
  arrange(Country, Year)
```

### 9. Summarize the data: `group_by`, `summarise`, `ungroup`

```{r}
# Want: Average GDP level of the world
d_gdp |> summarise(gdp_average = mean(GDP, na.rm = TRUE),
                   gdp_per_capita_average = mean(GDP_per_capita, na.rm = TRUE))
```

**Task:** Perform a data availability/ integrity check. Then aggregate the data into a new country-level dataset which contains the following indicators:

1.  Average development level from 1984 to 2022.

2.  Magnitude of growth from 1984 to 2022.

```{r}
# Data availability/ integrity check
d_gdp |>
  # Create a column that indicates whether the value is missing
  mutate(GDP_missing = as.numeric(is.na(GDP)), .after = GDP) |>
  group_by(Country) |>
  summarise(N_GDP_missing = sum(GDP_missing))

# ?as.numeric

```

```{r}
# Average development level
d_gdp |>
  group_by(Country) |>
  summarise(GDP_average = mean(GDP, na.rm = TRUE),
            GDPpc_average = mean(GDP_per_capita, na.rm = TRUE))

```

```{r}
# GDP growth and GDP per capita growth: comparing 2019 with 1984
d_gdp |>
  filter(Year >= 1984 & Year <= 2019) |>
  group_by(Country) |>
  arrange(Year) |>
  summarise(GDP_growth_2019_1984 = (last(GDP) - first(GDP)) / first(GDP),
            GDPpc_growth_2019_1984 = (last(GDP_per_capita) - first(GDP_per_capita)) / first(GDP_per_capita)) |>
  ungroup() |>
  arrange(Country)
```

## Final Notes

### Pipe `|>`

#### What is a pipe?

> R now provides a simple native forward pipe syntax `|>`. The simple form of the forward pipe [inserts the left-hand side as the first argument in the right-hand side call]{.underline}.

Let's elaborate this definition

```{r}
# What we have used
d_gdp |> filter(Country == "China")
# is equivalent to...
filter(d_gdp, Country == "China")
# ... is equivalent to
d_gdp |> filter(.data = _, Country == "China") 
# Note: You may use "_" as a placeholder of the object passed down through the pipe. But it should be used as a *named argument*. Upon a lookup in the tidyvese documentation (using ?filter) ".data" is the name of the first argument. This is a more advanced feature of this command. Understanding is optional. 
```

#### Why piping?

Pipe is useful when you are conducting a series of operation on your data but want to minimize the number of intermediate outputs produced. To

```{r}
# STEP 1: Subset variables
d_gdp <- d |> select(country_name, country_id, year, e_gdp, e_gdppc)

# STEP 2: Rename variables
d_gdp_renamed <- d_gdp |>
  rename("GDP" = "e_gdp", "GDP_per_capita" = "e_gdppc",
         "Country" = "country_name", "ID" = "country_id",
         "Year" = "year")

# STEP 3: Filter down to China
d_gdp_china <- d_gdp_renamed |> filter(Country == "China")

# STEP 4: Filter down to 2000 - 2005
d_gdp_china_2000_2005 <- d_gdp_china |> filter(Year >= 2000 & Year <= 2005)

d_gdp_china_2000_2005
```

As programmers, we face trade-offs. We want to work things out step-by-step. In this way, our code will look organized and readable for ourselves and other readers. However, the cost of a a step-by-step approach often is the growing size of intermediate outputs --- to pass down results from our intermediate steps, we have to temporarily save intermediate outputs. Doing so consume system resources (as they take up your Memory), makes it hard to navigate through your Environment, and is error-prone.

A pipe helps us maintain the step-by-step approach without creating many intermediate outputs. In our case, I can skip the intermediate outputs `d_gdp`, `d_gdp_renamed` and `d_gdp_china` with pipe.

```{r}
rm(d_gdp, d_gdp_renamed, d_gdp_china, d_gdp_china_2000_2005)

d_gdp_china_2000_2005 <- d |>
  # Subset variables
  select(country_name, country_id, year, e_gdp, e_gdppc) |>
  # Rename variables
  rename("GDP" = "e_gdp", "GDP_per_capita" = "e_gdppc",
         "Country" = "country_name", "ID" = "country_id",
         "Year" = "year") |>
  # Filter only observations from China
  filter(Country == "China") |>
  # Filter 2000 - 2005
  filter(Year >= 2000 & Year <= 2005)

d_gdp_china_2000_2005
```

#### `|>` v.s. `%>%`

When you look up online resources, you may see pipe written in a different way: `%>%`. This is the pipe operator that data scientists (including myself) have been familiar with for years. You may use `|>` and `%>%` interchangeably for basic use cases (which is pretty much everything we are doing in this course). For more advanced use cases, `%>%` is more powerful.

Read further: <https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/>

### To Create a New Object or Not

With pipe `|>`, we can maintain a step-by-step approach but skip some intermediate outputs. However, as our data processing task becomes more and more complicated, intermediate outputs are unavoidable. When do we want to create an intermediate output and when do we want to skip it? This is more arts than science. Here is my take:

1.  If I keep repeating some data wrangling steps for many downstream tasks, I would create an intermediate output and use it for all these downstream tasks.
2.  If I find some intermediate outputs no longer needed, I will remove them from my environment using `rm()` to keep my environment clean and to make space.
3.  Although I'd plan my data wrangling before I start the work, unexpected things happen. Sometimes, I figure I can merge some data wrangling steps to reduce intermediate outputs. Sometime, I suddenly realize some intermediate outputs are essential. This is a trial-and-error process.
4.  Perfectionism is unnecessary in data wrangling. Produce replicable code that you and readers can understand. But do not edit your code to make it "pretty" endlessly.

### Style

Where should you add *a space*? Where should you add *a line break*? Where should you add *a comment*? Where should you add *a section break*? These are questions concerning the *style* of your R code. Like writing articles, maintaining a good style when you write code helps you better communicate information with your readers and your future self.

Before talking about style, I should stress that the correctness of your syntax should always be prioritized over style. **One common mistake beginners make is to add spaces between functions and their arguments**. The typical error along this line is adding a space between a function and its arguments. For example, `filter(Year >= 2000 & Year <= 2005)` is correct, but `filter (Year >= 2000 & Year <= 2005)` is incorrect. The latter has a space between the function `filter` and its arguments `(Year >= 2000 & Year <= 2005)`. Take another example, `x[, 1]`, an expression that subset the first column of the data frame or matrix `x`, is correct. But `x [, 1]` is incorrect, because a space is added between the object `x` and the command that takes a subset from it `[, 1]`.

As we heavily use `tidyverse`, we will use `tidyverse`'s style guide: <https://style.tidyverse.org/>. The style guide touches upon several advanced R functionality, for now, we will focus on Sections 1 (Files), 4 (Pipes), and 5(`ggplot2`).
