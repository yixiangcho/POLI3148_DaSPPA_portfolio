---
title: "[INSERT YOUR NAME and UID]"
subtitle: "Problem Set 1+2 (15% + 15%)"
date: "Due: 2023-12-3 23:59 (HKT)"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, echo = FALSE, warning = FALSE)
```

## General Introduction

In this Problem Set, you will apply data science skills to wrangle and visualize the replication data of the following research article:

Cantú, F. (2019). The fingerprints of fraud: Evidence from Mexico's 1988 presidential election. *American Political Science Review*, *113*(3), 710-726.

## Requirements and Reminders

-   You are required to use **RMarkdown** to compile your answer to this Problem Set.

-   Two submissions are required (via Moodle)

    -   A `.pdf` file rendered by `Rmarkdown` that contains all your answer.

    -   A compressed (in `.zip` format) R project repo. The expectation is that the instructor can unzip, open the project file, knitr your `.Rmd` file, and obtain the exact same output as the submitted `.pdf` document.

-   The Problem Set is worth 30 points in total, allocated across 7 tasks. The point distribution across tasks is specified in the title line of each task. Within each task, the points are evenly distributed across sub-tasks. Bonus points (+5% max.) will be awarded to recognize exceptional performance.

-   Grading rubrics: Overall, your answer will be evaluated based on its quality in three dimensions

    -   Correctness and beauty of your outputs

    -   Style of your code

    -   Insightfulness of your interpretation or discussion

-   Unless otherwise specified, you are required to use functions from the `tidyverse` package to complete this assignments.

-   Fo some tasks, they may be multiple ways to achieve the same desired outcomes. You are encouraged to explore multiple methods. If you perform a task using multiple methods, do show it in your submission. You may earn bonus points for it.

-   You are encouraged to use Generative AI such as ChatGPT to assist with your work. However, you will need to acknowledge it properly and validate AI's outputs. You may attach selected chat history with the AI you use and describe how it helps you get the work done. Extra credit may be rewarded to recognize creative use of Generative AI.

-   This Problem Set is an individual assignment. You are expected to complete it independently. Clarification questions are welcome. Discussions on concepts and techniques related to the Problem Set among peers is encouraged. However, without the instructor's consent, sharing (sending and requesting) code and text that complete the entirety of a task is prohibited. You are strongly encouraged to use *CampusWire* for clarification questions and discussions.

\clearpage

## Background

In 1998, Mexico had a close presidential election. Irregularities were detected around the country during the voting process. For example, when 2% of the vote tallies had been counted, the preliminary results showed the PRI's imminent defeat in Mexico City metropolitan area and a very narrow vote margin between PRI and FDN. A few minutes later, the screens at the Ministry of Interior went blank, an event that electoral authorities justified as a technical problem caused by an overload on telephone lines. The vote count was therefore suspended for three days, despite the fact that opposition representatives found a computer in the basement that continued to receive electoral results. Three days later, the vote count resumed, and soon the official announced PRI's winning with 50.4% of the vote.

*What happened on that night and the following days? Were there electoral fraud during the election?* A political scientist, Francisco Cantú, unearths a promising dataset that could provide some clues. At the National Archive in Mexico City, Cantú discovered about 53,000 vote tally sheets. Using machine learning methods, he detected that a significant number of tally sheets were *altered*! In addition, he found evidence that the altered tally sheets were biased in favor of the incumbent party. In this Problem Set, you will use Cantú's replication dossier to replicate and extend his data work.

Please read Cantú (2019) for the full story. And see Figure 1 for a few examples of altered (fraudulent) tallies.

![Examples of altered tally sheets (reproducing Figure 1 of Cantú 2018)](image/fraud.png){width="260"}

\clearpage

## Task 0. Loading required packages (3pt)

For Better organization, it is a good habit to load all required packages up front at the start of your document. Please load the all packages you use throughout the whole Problem Set here.

```{r, echo=TRUE}
# YOUR CODE HERE
library(tidyverse)
library(dplyr)
library(stringr)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(sf)
```

\clearpage

## Task 1. Clean machine classification results (3pt)

Cantú applys machine learning models to 55,334 images of tally sheets to detect signs of fraud (i.e., alteration). The machine learning model returns results recorded in a table. The information in this table is messy and requires data wrangling before we can use them.

### Task 1.1. Load classified images of tally sheets

The path of the classified images of tally sheets is `data/classification.txt`. Your first task is loading these data onto R using a `tidyverse` function. Name it `d_tally`.

Note:

-   Although the file extension of this dataset is `.txt`, you are recommended to use the `tidyverse` function we use for `.csv` files to read it.

-   Unlike the data files we have read in class, this table has *no column names*. Look up the documentation and find a way to handle it.

-   There will be three columns in this dataset, name them `name_image`, `label`, and `probability`.

Print your table to show your output.

```{r, echo=TRUE}
# YOUR CODE HERE
d_tally<-read_csv("data/classification.txt")
colnames(d_tally) <- c("name_image", "label", "probability")
print(d_tally)
```

\clearpage

### Note 1. What are in this dataset?

Before you proceed, let me explain the meaning of the three variables.

-   `name_image` contains the names of of the tallies' image files (as you may infer from the `.jpg` file extensions. They contain information about the locations where each of the tally sheets are produced.

-   `label` is a machine-predicted label indicating whether a tally is fraudulent or not. `label = 1` means the machine learning model has detected signs of fraud in the tally sheet. `label = 0` means the machine detects no sign of fraud in the tally sheet. In short, `label = 1` means fraud; `label = 0` means no fraud.

-   `probability` indicates the machine's certainty about its predicted `label` (explained above). It ranges from 0 to 1, where higher values mean higher level of certainty.

Interpret `label` and `probability` carefully. Two examples can hopefully give you clues about their correct interpretation. In the first row, `label = 0` and `probability = 0.9991`. That means the machine thinks this tally sheet is NOT FRAUDULENT with a probability of 0.9991. Then, the probability that this tally sheet is fraudulent is `1 - 0.9991 = 0.0009`. Take another example, in the 11th row, `label = 1` and `probability = 0.935`. This means the machine thinks this tally sheet IS FRAUDULENT with a probability of 0.935. Then, the probability that it is NOT FRAUDULENT is `1 - 0.9354 = 0.0646`.

\clearpage

### Task 1.2. Clean columns `label` and `probability`

As you have seen in the printed outputs, columns `label` and `probability` are read as `chr` variables when they are actually numbers. A close look at the data may tell you why --- they are "wrapped" by some non-numeric characters. In this task, you will clean these two variables and make them valid numeric variables. You are required to use `tidyverse` operations to for this task. Show appropriate summary statistics of `label` and `probability` respectively after you have transformed them into numeric variables.

```{r,echo=TRUE}
# YOUR CODE HERE

d_tally$label <- as.numeric(str_remove_all(d_tally$label, "\\[\\[|\\]\\]"))
d_tally$probability <- as.numeric(str_remove_all(d_tally$probability, "\\[\\[|\\]\\]"))
print(d_tally)
```

\clearpage

### Task 1.3. Extract state and district information from `name_image`

As explained in the note, the column `name_image`, which has the names of tally sheets' images, contains information about locations where the tally sheets are produced. Specifically, the first two elements of these file names indicates the **states'** and districts' identifiers respectively, for example, `name_image = "Aguascalientes_I_2014-05-26 00.00.10.jpg"`. It means this tally sheet is produced in state **`Aguascalientes`**, district **`I`**. In this task, you are required to obtain this information. Specifically, create two columns named `state` and `district` as state and district identifiers respectively. You are required to use `tidyverse` functions to perform the task.

```{r, echo=TRUE}
# YOUR CODE HERE

# Method 1
d_tally <- d_tally |>
  mutate(
    state = str_extract(name_image, "^[^_]+"),
    district = str_extract(name_image, "(?<=_)[^_]+(?=_)")
  )
print(d_tally)

# Method 2
#d_tally <- d_tally |>
#  separate(name_image, into = c("state", "district"), sep = "_", remove = FALSE)
#print(d_tally)
```

\clearpage

### Task 1.4. Re-code a state's name

One of the states (in the newly created column `state`) is coded as "`Estado de Mexico`." The researchers decide that it should instead re-coded as "**`Edomex`**." Please use a `tidyverse` function to perform this task.

Hint: Look up functions `ifelse` and `case_match`.

```{r, echo=TRUE}
# YOUR CODE HERE

# Method 1
d_tally <- d_tally |>
  mutate(
    state = case_when(
      state == "Estado de Mexico" ~ "Edomex",
      TRUE ~ state))

# Method 2
#d_tally <- d_tally |>
#          mutate(state = ifelse(state == "Estado de Mexico", "Edomex", state))
#print(d_tally)
```

\clearpage

### Task 1.5. Create a *probability of fraud* indicator

As explained in Note 1, we need to interpret `label` and `probability` with caution, as the meaning of `probability` is conditional on the value of `label`. To avoid confusion in the analysis, your next task is to create a column named `fraud_proba` which indicates the probability that a tally sheet is is fraudulent. After you have created the column, drop the `label` and `probability` columns.

*Hint: Look up the `ifelse` function and the `case_when` function (but you just need either one of them).*

```{r, echo=TRUE}
# YOUR CODE HERE

# Method 1
d_tally <- d_tally |>
  mutate(
    fraud_proba = ifelse(label == 0, 1 - probability, probability),
    fraud_proba = round(fraud_proba, 4)
    ) |>
  select(-label, -probability)
print(d_tally)

# Method 2
# d_tally <- d_tally |>
#   mutate(
#     fraud_proba = case_when(
#       label == 0 ~ 1 - probability,
#       TRUE ~ probability),
#     fraud_proba = round(fraud_proba, 4)) |>
#   select(-label, -probability)
#print(d_tally)
```

\clearpage

### Task 1.6. Create a binary *fraud* indicator

In this task, you will create a binary indicator called `fraud_bin` in indicating whether a tally sheet is fraudulent. Following the researcher's rule, we consider a tally sheet fraudulent only when the machine thinks it is at least 2/3 likely to be fraudulent. That is, `fraud_bin` is set to TRUE when `fraud_proba` is greater to `2/3` and is FALSE otherwise.

```{r, echo=TRUE}
# YOUR CODE HERE
d_tally <- d_tally |>
  mutate(
    fraud_bin = fraud_proba > 2/3)
print(d_tally)
```

\clearpage

## Task 2. Visualize machine classification results (3pt)

In this section, you will visualize the `tally` dataset that you have cleaned in Task 1. Unless otherwise specified, you are required to use the `ggplot` packages to perform all the tasks.

### Task 2.1. Visualize distribution of `fraud_proba`

How is the predicted probability of fraud (`fraud_proba`) distributed? Use two methods to visualize the distribution. Remember to add informative labels to the figure. Describe the plot with a few sentences.

```{r, echo=TRUE, fig.width=5, fig.height=4, out.width="50%", fig.align='center'}
# YOUR CODE HERE

# Method 1: Histogram
hist_plot <- ggplot(d_tally, aes(x = fraud_proba, fill = fraud_bin)) +
  geom_histogram(binwidth = 0.3, position = "identity", alpha = 0.6) +
  labs(title = "Distribution of Predicted Probability",
       x = "Predicted Probability (fraud_proba)",
       y = "Frequency") +
  scale_fill_manual(values = c("FALSE" = "red", "TRUE" = "green")) +
  theme_minimal()

# Method 2: Density Plot
density_plot <- ggplot(d_tally, aes(x = fraud_proba, fill = fraud_bin)) +
  geom_density(alpha = 0.6) +
  labs(title = "Distribution of Predicted Probability",
       x = "Predicted Probability (fraud_proba)",
       y = "Density") +
  scale_fill_manual(values = c("FALSE" = "red", "TRUE" = "green")) +
  theme_minimal()

# Placing the graphs
grid.arrange(hist_plot, density_plot, ncol = 2)

#The histogram: a binned representation of probability values.
#The density plot: a smoother view of the distribution, emphasizing the overall shape.
#The green areas: the portion of tallies predicted as fraudulent.
```

\clearpage

### Task 2.2. Visualize distribution of `fraud_bin`

How many tally sheets are fraudulent and how many are not? We may answer this question by visualizing the binary indicator of tally-level states of fraud. Use at least two methods to visualize the distribution of `fraud_bin`. Remember to add informative labels to the figure. Describe your plots with a few sentences.

```{r, echo=TRUE, fig.width=5, fig.height=4, out.width="50%", fig.align='center'}
# YOUR CODE HERE

# Method 1: Bar Plot
bar_plot <- ggplot(d_tally, aes(x = factor(fraud_bin), fill = factor(fraud_bin))) +
  geom_bar() +
  labs(title = "Distribution of Fraudulent Tally Sheets",
       x = "Fraudulent (fraud_bin)",
       y = "Count") +
  scale_fill_manual(values = c("FALSE" = "blue", "TRUE" = "yellow")) +
  theme_minimal()

# Method 2: Pie Chart
pie_chart <- ggplot(d_tally, aes(x = "", fill = factor(fraud_bin))) +
  geom_bar(width = 1, stat = "count") +
  coord_polar("y") +
  labs(title = "Distribution of Fraudulent Tally Sheets",
       fill = "Fraudulent (fraud_bin)",
       x = NULL,
       y = NULL) +
  scale_fill_manual(values = c("FALSE" = "blue", "TRUE" = "yellow")) +
  theme_minimal()

# Placing the graphs
grid.arrange(bar_plot, pie_chart, ncol = 2)

#Bar plot: the blue and yellow bars represent non-fraudulent and fraudulent tally sheets.
#Pie chart: a circular visualization, the yellow slice indicates proportion of fraudulent sheets relative to the whole dataset.
```

The figure below serve as a reference. Feel free to try alternative approach(es) to make your visualization nicer and more informative.

\clearpage

### Task 2.3. Summarize prevalence of fraud by state

Next, we will examine the between-state variation with regards to the prevalence of election fraud. In this task, you will create a new object that contains two state-level indicators regarding the prevalence of election fraud: The count of fraudulent tallies and the proportion of fraudulent tallies.

```{r, echo=TRUE}
# YOUR CODE HERE
state_level_indicators_summary <- d_tally |>
  group_by(state) |>
  summarize(
    count_fraudulent = sum(fraud_bin),
    proportion_fraudulent = mean(fraud_bin) * 100  # Multiply by 100 for percentage
  )
print(state_level_indicators_summary)
```

\clearpage

### Task 2.4. Visualize frequencies of fraud by state

Using the new data frame created in Task 2.3, please visualize the *frequencies* of fraudulent tallies of every state. Describe the key takeaway from the visualization with a few sentences.

Feel free to try alternative approach(es) to make your visualization nicer and more informative.

```{r}
# YOUR CODE HERE

bar_plot <- ggplot(state_level_indicators_summary, aes(x = state, y = count_fraudulent, fill = state)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Prevalence of Fraud",
       x = "State",
       y = "Count of Fraudulent Tallies") +
  theme_minimal()
print(bar_plot)

#The bar plot compares the frequencies of fraudulent tallies across different states.
#Each bar: Different states.
#Height: the count of fraudulent tallies in that state.
```

\clearpage

### Task 2.5. Visualize proportions of fraud by state

Using the new data frame created in Task 2.3, please visualize the *proportion of* of fraudulent tallies of every state. Describe the key takeaway from the visualization with a few sentences.

Feel free to try alternative approach(es) to make your visualization nicer and more informative.

```{r}
# YOUR CODE HERE

bar_plot <- ggplot(state_level_indicators_summary, aes(x = proportion_fraudulent, y = state, fill = state)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Prevalence of Fraud",
       x = "Proportion of Fraudulent Tallies (%)",
       y = "State") +
  scale_fill_manual(values = c("NY" = "blue", "CA" = "red", "TX" = "green")) +  
  # Customize colors
  theme_minimal()
print(bar_plot)

#The horizontal bar: the proportions of fraudulent tallies for each state
#Each bar represents a state, with the length of the bar corresponding to the proportion of fraudulent tallies.
```

\clearpage

### Task 2.6. Visualize both proportions & frequencies of fraud by state

Create data visualization to show BOTH the *proportions* and *frequencies* of fraudulent tally sheets by state in one figure. Include annotations to highlight states with the highest level of fraud. Add informative labels to the figure. Describe the takeaways from the figure with a few sentences.

```{r, echo=TRUE}
# YOUR CODE HERE

# Combined bar plot
combined_plot <- ggplot(state_level_indicators_summary, aes(x = state)) +
  geom_bar(aes(y = count_fraudulent / max(count_fraudulent), fill = "Frequency"), stat = "identity", position = "dodge", width = 0.7) +
  geom_bar(aes(y = proportion_fraudulent / max(proportion_fraudulent), fill = "Proportion"), stat = "identity", position = "dodge", width = 0.5) +
  scale_fill_manual(values = c("Frequency" = "purple", "Proportion" = "green")) +
  labs(title = "Fraudulent Tally Sheets by State",
       x = "State",
       y = "Normalized Scale") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# Annotate states with the highest fraud
combined_plot + 
  annotate("text", x = state_level_indicators_summary$state, y = 1.1, 
           label = state_level_indicators_summary$count_fraudulent, color = "purple", size = 2) +
  annotate("text", x = state_level_indicators_summary$state, y = 1.05, 
           label = paste0(round(state_level_indicators_summary$proportion_fraudulent, 2), "%"), color = "green", size = 2)

#Purple bars: the raw count of fraudulent tallies.
#Green bars: the proportion of fraud relative to the maximum value for each metric.
#Emphasize: states with the highest fraud levels.
```

\clearpage

## Task 3. Clean vote return data (3pt)

Your next task is to clean a different dataset from the researchers' replication dossier. Its path is `data/Mexican_Election_Fraud/dataverse/VoteReturns.csv`. This dataset contains information about vote returns recorded in every tally sheet. This dataset is essential for the replication of Figure 4 in the research article.

### Task 3.1. Load vote return data

Load the dataset onto your R environment. Name this dataset `d_return`. Show summary statistics of this dataset and describe the takeaways using a few sentences.

```{r, echo=TRUE}
# YOUR CODE
d_return<-read_csv("data/VoteReturns.csv")
summary(d_return)

#The dataset has a total of 53,499 entries
#The columns 'p1' to 'pfcrn3' represent the votes for different political parties and candidates.
#Some columns, such as 'ppsm2', 'ppm2', and 'presidente', have missing values
```

\clearpage

### Note 2. What are in this dataset?

This table contains a lot of different variables. The researcher offers no comprehensive documentation to tell us what every column means. For the sake of this problem set, you only need to know the meanings of the following columns:

-   `foto` is an identifier of the images of tally sheets in this dataset. We will need it to merge this dataset with the `d_tally` data.

-   `edo` contains the names of states.

-   `dto` contains the names of districts (in Arabic numbers).

-   `salinas`, `clouthier`, and `ibarra` contain the counts of votes (as recorded in the tally sheets) for presidential candidates Salinas (PRI), Cardenas (FDN), and Clouthier (PAN). In addition, the summation of all three makes the total number of **presidential votes**.

-   `total` contains the total number of **legislative votes**.

\clearpage

### Task 3.2. Recode names of states

A state whose name is `Chihuahua` is mislabelled as `Chihuhua`. A state whose name is currently `Edomex` needs to be recoded to `Estado de Mexico`. Please re-code the names of these two states accordingly.

```{r, echo=TRUE}
# YOUR CODE

d_return <- d_return |>
  mutate(edo = case_when(
    edo == "Chihuhua" ~ "Chihuahua",
    edo == "Edomex" ~ "Estado de Mexico",
    TRUE ~ edo
  ))
print(d_return)
```

\clearpage

### Task 3.3. Recode districts' identifiers

Compare how districts' identifiers are recorded differently in the tally (`d_tally`) from vote return (`d_return`) datasets. Specifically, in the `d_tally` dataset, `district` contains Roman numbers while in the `d_return` dataset, `dto` contains Arabic numbers. Recode districts' identifiers [in the `d_return` dataset]{.underline} to match those in the `d_tally` dataset. To complete this task, first summarize the values of the two district identifier columns in the two datasets respectively to verify the above claim. Then do the requested conversion.

```{r, echo=TRUE}
# YOUR CODE HERE

# Function to convert Arabic numbers to Roman numbers
arabic_to_roman <- function(number) {
  if (is.na(number)) {
    return(NA)
  }

  roman_data <- data.frame(
    arabic = c(1000, 900, 500, 400, 100, 90, 50, 40, 10, 9, 5, 4, 1),
    roman = c("M", "CM", "D", "CD", "C", "XC", "L", "XL", "X", "IX", "V", "IV", "I")
  )

  result <- ""
  for (i in 1:nrow(roman_data)) {
    while (number >= roman_data$arabic[i]) {
      result <- paste0(result, roman_data$roman[i])
      number <- number - roman_data$arabic[i]
    }
  }

  return(result)
}


# Recode dto column and rename it to dto
d_return <- d_return |>
  mutate(dto = map_chr(dto, arabic_to_roman))

head(d_return)
```

\clearpage

### Task 3.4. Create a `name_image` identifier for the `d_return` dataset

In the `d_return` dataset, create a column named `name_image` as the first column. The column concatenate values in the three columns: `edo`, `dto`, and `foto` with an underscore `_` as separators.

```{r, echo=TRUE}
# YOUR CODE HERE

# Create name_image column for d_return
d_return <- d_return |>
  mutate(name_image = paste(edo, dto, foto, sep = "_"))
```

\clearpage

### Task 3.5. Wrangle the `name_image` column in two datasets

As a final step before merging `d_return` and `d_tally`, you are required to perform the following data wrangling. For the `name_image` column in BOTH `d_return` and `d_tally`:

-   Convert all characters to lower case.

-   Remove ending substring `.jpg`.

```{r, echo=TRUE}
# YOUR CODE HERE

# Convert name_image column to lower case and remove ".jpg" ending substring
d_return <- d_return |>
  mutate(name_image = tolower(name_image),
         name_image = str_replace(name_image, "\\.jpg$", ""))

d_tally <- d_tally |>
  mutate(name_image = tolower(name_image),
         name_image = str_replace(name_image, "\\.jpg$", ""))
```

\clearpage

### Task 3.6 Join classification results and vote returns

After you have successfully completed all the previous steps, join `d_return` and `d_tally` by column `name_image`. This task contains two part. First, use appropriate `tidyverse` functions to answer the following questions:

-   How many rows are in `d_return` but not in `d_tally`? Which states and districts are they from?

-   How many rows are in `d_tally` but not in `d_return`? Which states and districts are they from?

```{r, echo=TRUE}
# YOUR CODE HERE

# Join d_return and d_tally by name_image
joined_data <- left_join(d_return, d_tally, by = "name_image")

# Identify rows in d_return but not in d_tally
rows_in_return_not_in_tally <- anti_join(d_return, d_tally, by = "name_image")

# Identify rows in d_tally but not in d_return
rows_in_tally_not_in_return <- anti_join(d_tally, d_return, by = "name_image")

# Count the number of rows in each set
num_rows_in_return_not_in_tally <- nrow(rows_in_return_not_in_tally)
num_rows_in_tally_not_in_return <- nrow(rows_in_tally_not_in_return)

# Display the results
cat("Number of rows in d_return but not in d_tally:", num_rows_in_return_not_in_tally, "\n")
cat("Number of rows in d_tally but not in d_return:", num_rows_in_tally_not_in_return, "\n")

# States and districts in d_return but not in d_tally
cat("States and districts in d_return but not in d_tally:\n")
print(rows_in_return_not_in_tally)

# States and districts in d_tally but not in d_return
cat("States and districts in d_tally but not in d_return:\n")
print(rows_in_tally_not_in_return)

```

Second, create a dataset call `d` by joining `d_return` and `d_tally` by column `name_image`. `d` contains rows whose identifiers appear in *both* datasets and columns from *both* datasets.

```{r, echo=TRUE}
# YOUR CODE HERE

# Join d_return and d_tally by name_image
d <- inner_join(d_return, d_tally, by = "name_image")

# Display the structure of d
str(d)
```

\clearpage

## Task 4. Visualize distributions of fraudulent tallies across candidates (6pt)

In this task, you will visualize the distributions of fraudulent tally sheets across three presidential candidates: **Sarinas (PRI)**, **Cardenas (FDN)**, and **Clouthier (PAN)**. The desired output of is reproducing and extending Figure 4 in the research article (Cantu 2019, pp. 720).

### Task 4.1. Calculate vote proportions of Salinas, Clouthier, and Cardenas

Before getting to the visualization, you should first calculate the proportion of votes (among all) received by the three candidates of interest. As additional background information, there are two more presidential candidates in this election, whose votes received are recorded in `ibarra` and `castillo` respectively. Please perform the tasks in the following two steps on the `d` dataset:

-   Create a new column named `total_president` as an indicator of the total number of votes of the 5 presidential candidates.

-   Create three columns `salinas_prop`, `cardenas_prop`, and `clouthier_prop` that indicate the proportions of the votes these three candidates receive respectively.

```{r, echo=TRUE}
# YOUR CODE HERE

# Step 1: Create a new column named total_president
d$total_president <- rowSums(d[, c("pri", "pfcrn", "pan", "ibarra", "castillo")], na.rm = TRUE)

# Step 2: Create three columns salinas_prop, cardenas_prop, and clouthier_prop
d$salinas_prop <- d$pri / d$total_president
d$cardenas_prop <- d$pfcrn / d$total_president
d$clouthier_prop <- d$pan / d$total_president

```

\clearpage

### Task 4.2. Replicate Figure 4

Based on all the previous step, reproduce Figure 4 in Cantu (2019, pp. 720).

```{r, echo=TRUE}
# YOUR CODE HERE

# histogram Salinas
salinas_plot <- ggplot(d, aes(x = salinas_prop)) +
  geom_histogram(binwidth = 0.02, fill = "blue", alpha = 0.7) +
  labs(title = "Distribution of Vote Shares for Salinas (PRI)",
       x = "Vote Share",
       y = "Frequency") +
  theme_minimal()

# histogram  Cardenas
cardenas_plot <- ggplot(d, aes(x = cardenas_prop)) +
  geom_histogram(binwidth = 0.02, fill = "yellow", alpha = 0.7) +
  labs(title = "Distribution of Vote Shares for Cardenas (FDN)",
       x = "Vote Share",
       y = "Frequency") +
  theme_minimal()

# histogram Clouthier
clouthier_plot <- ggplot(d, aes(x = clouthier_prop)) +
  geom_histogram(binwidth = 0.02, fill = "green", alpha = 0.7) +
  labs(title = "Distribution of Vote Shares for Clouthier (PAN)",
       x = "Vote Share",
       y = "Frequency") +
  theme_minimal()

multiplot <- cowplot::plot_grid(salinas_plot, cardenas_plot, clouthier_plot, ncol = 3)

print(multiplot)
```

Note: Your performance in this task will be mainly evaluated based on your output's similarity with the original figure. Pay attention to the details. For your reference, below is a version created by the instructor.

\clearpage

### Task 4.3. Discuss and extend the reproduced figure

Referring to your reproduced figures and the research articles, in what way is the researcher's argument supported by this figure? Make an alternative visualization design that can substantiate and even augment the current argument. After you have shown your alternative design, in a few sentences, describe how your design provides visual aid as effectively as or more effectively than the original figure.

**Note:** Feel free to make *multiple* alternative designs to earn bonus credits. However, please be selective. Only a design with major differences from the existing ones can be counted as an alternative design.

```{r, echo=TRUE}
# YOUR CODE HERE

#The initial reproduction: histograms illustrating the distribution of vote shares for each candidate.
#Histograms provide a visual representation of the spread and concentration of vote shares for each candidate.

#Alternative Design: Stacked Area Chart
#A stacked area chart can illustrate the cumulative distribution of vote shares over time, providing a dynamic perspective on candidate support.
#A stacked area chart can be effective in showing how vote shares evolve over time, allowing for a temporal analysis of candidate support. 
#The stacked area chart introduces a temporal dimension to candidate support.

# Create a stacked area chart
area_chart <- ggplot(d, aes(x = reorder(name_image, desc(salinas_prop)), y = salinas_prop, fill = "Salinas")) +
  geom_area() +
  geom_area(aes(y = cardenas_prop, fill = "Cardenas")) +
  geom_area(aes(y = clouthier_prop, fill = "Clouthier")) +
  labs(title = "Cumulative Distribution of Vote Shares for Presidential Candidates",
       x = "Time",
       y = "Cumulative Vote Share") +
  scale_fill_manual(values = c(Salinas = "blue", Cardenas = "red", Clouthier = "green"), name = "Candidate") +
  theme_minimal() +
  theme(legend.position = "top")

print(area_chart)
```

**Note:** Feel free to suggest *multiple* alternative designs to earn bonus credits. However, please be selective. Only a design with major differences from the existing ones can be counted as an alternative design.

\clearpage

## Task 5. Visualize the discrepancies between presidential and legislative Votes (6pt)

In this task, you will visualize the differences between the number of presidential votes across tallies. The desired output of is reproducing and extending Figure 5 in the research article (Cantu 2019, pp. 720).

### Task 5.1. Get district-level discrepancies and fraud data

As you might have noticed in the caption of Figure 5 in Cantu (2019, pp. 720), the visualized data are aggregated to the *district* level. In contrast, the unit of analysis in the dataset we are working with, `d`, is *tally*. As a result, the first step of this task is to aggregate the data. Specifically, please aggregate `d` into a new data frame named `sum_fraud_by_district`, which contains the following columns:

-   `state`: Names of states

-   `district`: Names of districts

-   `vote_president`: Total numbers of presidential votes

-   `vote_legislature`: Total numbers of legislative votes

-   `vote_diff`: Total number of presidential votes minus total number of legislative votes

-   `prop_fraud`: Proportions of fraudulent tallies (hint: using `fraud_bin`)

```{r, echo=TRUE}
# YOUR CODE HERE

# Aggregate data to get district-level discrepancies and fraud data
sum_fraud_by_district <- d |>
  group_by(state, district) |>
  summarize(
    vote_president = sum(total),          # Total presidential votes
    vote_legislature = sum(total1),        # Total legislative votes
    vote_diff = sum(total) - sum(total1),  # Presidential votes minus legislative votes
    prop_fraud = mean(fraud_bin)           # Proportion of fraudulent tallies
  ) |>
  ungroup()

print(sum_fraud_by_district)
```

\clearpage

### Task 5.2. Replicate Figure 5

Based on all the previous step, reproduce Figure 5 in Cantu (2019, pp. 720).

```{r, echo=TRUE}
# YOUR CODE HERE

# Replicate Figure 5
ggplot(sum_fraud_by_district, aes(x = vote_legislature, y = vote_president, color = prop_fraud)) +
  geom_point(size = 3) +
  scale_color_gradient(low = "blue", high = "red") +
  labs(
    title = "Total Number of District Votes for Presidential and Legislative Elections. Mexico, 1988",
    x = "Total Legislative Votes",
    y = "Total Presidential Votes",
    color = "Proportion of Fraudulent Tallies"
  ) +
  theme_minimal()
```

**Note 1:** Your performance in this task will be mainly evaluated based on your output's similarity with the original figure. Pay attention to the details.

**Note 2:** The instructor has detected some differences between the above figure with Figure 5 on the published article. Please use the instructor's version as your main benchmark.

\clearpage

### Task 5.3. Discuss and extend the reproduced figure

Referring to your reproduced figures and the research articles, in what way is the researcher's argument supported by this figure? Make an alternative visualization design that can substantiate and even augment the current argument. After you have shown your alternative design, in a few sentences, describe how your design provides visual aid as effectively as or more effectively than the original figure.

**Note:** Feel free to make *multiple* alternative designs to earn bonus credits. However, please be selective. Only a design with major differences from the existing ones can be counted as an alternative design.

```{r, echo=TRUE}
# YOUR CODE HERE

# Alternative Design: Grouped Bar Chart
ggplot(sum_fraud_by_district, aes(x = district)) +
  geom_bar(aes(y = vote_president, fill = prop_fraud), position = "dodge", stat = "identity") +
  geom_bar(aes(y = -vote_legislature, fill = prop_fraud), position = "dodge", stat = "identity") +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(
    title = "Comparison of Presidential and Legislative Votes with Fraudulent Tallies by District",
    x = "District",
    y = "Total Votes",
    fill = "Proportion of Fraudulent Tallies"
  ) +
  theme_minimal() +
  theme(legend.position = "top", legend.title = element_blank())

#The scatter plot effectively highlights the relationship between these variables, emphasizing regions where discrepancies are more pronounced.

#An alternative design could be a grouped bar chart, where each district is represented by a pair of bars: one for presidential votes and one for legislative votes.

#The height of the bar: represents the total number of votes in that category

#Colors within each bar segments: the proportion of fraudulent tallies.

#This alternative design provides a more direct comparison between presidential and legislative votes in each district while maintaining the focus on the proportion of fraudulent tallies. 

#The alternative design is effective as it complements the scatter plot by offering a different perspective, making it easier to identify patterns and discrepancies across districts.
```

\clearpage

## Task 6. Visualize the spatial distribution of fraud (6pt)

In this final task, you will visualize the spatial distribution of electoral fraud in Mexico. The desired output of is reproducing and extending Figure 3 in the research article (Cantu 2019, pp. 720).

### Note 3. Load map data

As you may recall, map data can be stored and shared in **two** ways. The simpler format is a table where each row has information of a point that "carves" the boundary of a geographic unit (a Mexican state in our case). In this type of map data, a geographic unit is is represented by multiple rows. Alternatively, a map can be represented by a more complicated and more powerful format, where each geographic unit (a Mexican state in our case) is represented by an element of a `geometry` column. For this task, I provide you with a state-level map of Mexico represented by both formats respectively.

Below the instructor provide you with the code to load the maps stored under the two formats respectively. Please run them before starting to work on your task.

```{r, echo=TRUE, results='hide'}
# IMPORTANT: Remove eval=FALSE above when you start this part!

# Load map (simple)
map_mex <- read_csv("data/map_mexico/map_mexico.csv")
# Load map (sf): You need to install and load library "sf" in advance
map_mex_sf <- st_read("data/map_mexico/shapefile/gadm36_MEX_1.shp")
map_mex_sf <- st_simplify(map_mex_sf, dTolerance = 100)

# Bonus question: the st_simplify function is applied to map_mex_sf with a tolerance of 100. This function simplifies the geometry of spatial objects, reducing the number of vertices while preserving the overall shape.
# Lower values of the dTolerance parameter retain more detail but may result in larger file sizes, while higher values reduce detail but can lead to smaller file sizes.
```

**Bonus question**: Explain the operations on `map_mex_sf` in the instructor's code above.

**Note**: The map (sf) data we use are from <https://gadm.org/download_country_v3.html>.

\clearpage

### Task 6.1. Reproduce Figure 3 with `map_mex`

In this task, you are required to reproduce Figure 3 with the `map_mex` data.

Note:

-   Your performance in this task will be mainly evaluated based on your output's similarity with the original figure. Pay attention to the details. For your reference, below is a version created by the instructor.

-   Hint: Check the states' names in the map data and the electoral fraud data. Recode them if necessary.

```{r, echo=TRUE}
# YOUR CODE HERE

# Convert map_mex to an sf object
map_mex_sf <- st_as_sf(map_mex, coords = c("long", "lat"), crs = st_crs(4326))

# Merge electoral fraud data with map data
map_fraud <- left_join(map_mex_sf, sum_fraud_by_district, by = c("state_name" = "state"))

# Check for missing data in the merged dataset
missing_data <- sum(is.na(map_fraud$prop_fraud))
if (missing_data > 0) {
  warning(paste("There are", missing_data, "states with missing data. Check for discrepancies in state names."))
}

# Plot the map
ggplot() +
  geom_sf(data = map_fraud, aes(fill = prop_fraud), color = "white", size = 0.2) +
  scale_fill_gradient(name = "Proportion of Altered Tallies", low = "lightblue", high = "darkred") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  ggtitle("Rates of Tallies Classified as Altered by State")

```

\clearpage

### Task 6.2. Reproduce Figure 3 with `map_mex_sf`

In this task, you are required to reproduce Figure 3 with the `map_mex` data.

Note:

-   Your performance in this task will be mainly evaluated based on your output's similarity with the original figure. Pay attention to the details. For your reference, below is a version created by the instructor.

-   Hint: Check the states' names in the map data and the electoral fraud data. Recode them if necessary.

```{r, echo=TRUE}
# YOUR CODE HERE

# Check the structure of map_mex_sf
str(map_mex_sf)

# Merge electoral fraud data with map data
map_fraud <- left_join(map_mex_sf, sum_fraud_by_district, by = c("state_name_official" = "state"))

# Check for missing values in the merged data
missing_values <- sum(is.na(map_fraud$prop_fraud))

if (missing_values > 0) {
  cat()
}

# Plot the spatial distribution of fraud
ggplot(map_fraud) +
  geom_sf(aes(fill = prop_fraud), color = "white", lwd = 0.2) +
  scale_fill_gradient(name = "Proportion of Fraudulent Tallies", low = "lightblue", high = "darkred") +
  theme_minimal() +
  labs(title = "Rates of Tallies Classified as Altered by State")
```

\clearpage

### Task 6.3. Discuss and extend the reproduced figures

Referring to your reproduced figures and the research articles, in what way is the researcher's argument supported by this figure? Make an alternative visualization design that can substantiate and even augment the current argument. After you have shown your alternative design, in a few sentences, describe how your design provides visual aid as effectively as or more effectively than the original figure.

**Note:** Feel free to make *multiple* alternative designs to earn bonus credits. However, please be selective. Only a design with major differences from the existing ones can be counted as an alternative design.

```{r, echo=TRUE}
# YOUR CODE HERE

# Alternative Design: Facetted Choropleth Map with Mini-Histograms
ggplot(map_fraud) +
  geom_sf(aes(fill = prop_fraud), color = "white", lwd = 0.2) +
  scale_fill_gradient(name = "Proportion of Fraudulent Tallies", low = "lightblue", high = "darkred") +
  facet_wrap(~state_name_official, scales = "fixed", ncol = 4) +
  theme_minimal() +
  labs(title = "Rates of Tallies Classified as Altered by State")

#The researchers’ map: Visual representation of the spatial distribution of fraudulent tallies

#Alternative Design:

#Choropleth map but with an additional facetted approach: each state has its own mini-histogram or bar chart showing the distribution of fraud proportions within that state.

#This provides a more nuanced view of fraud distribution within each state, shows the variation in fraud proportions across different regions.

#This alternative design provides a state-level breakdown, allowing viewers to know patterns and variations within each state. The mini-histograms within each facet offer a more detailed perspective on the distribution of fraud proportions.
```
